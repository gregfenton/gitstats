#!/usr/bin/env python

"""
Copyright (c) 2007-2011 Heikki Hokkanen <hoxu@users.sf.net>
& others (see doc/author.txt).

GPLv2 / GPLv3
"""

from datetime import datetime, timedelta
import getopt  # todo: replace with argparse
import glob
import os
import pickle
import re
import shutil
import subprocess
import sys
import time
import zlib
from collections import defaultdict
import urllib
import tempfile

GNUPLOT_COMMON = \
    'set terminal png transparent size 640,240\nset size 1.0,1.0\n'
WEEKDAYS = ('Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun')

# By default, gnuplot is searched from path, but can be overridden with the
# environment variable "GNUPLOT"
gnuplot_cmd = 'gnuplot'
if 'GNUPLOT' in os.environ:
    gnuplot_cmd = os.environ['GNUPLOT']

conf = {
    'max_domains': 10,
    'style': 'gitstats.css',
    'max_authors': 20,
    'authors_top': 5,
    'linear_linestats': 1,
    'project_name': '',
    'exclude_extensions': 'png,gif,pdf,json,csv,jpg,sh,txt,xml',
    'exclude_directories': 'src/test/',
}


def getpipeoutput(cmds):
    """
    Accept a series of commands.

    Execute each command in order, piping the output of
    each into the subsequent command.
    """
    proc = subprocess.Popen(cmds[0], stdout=subprocess.PIPE, shell=True)
    prev = proc
    for x in cmds[1:]:
        proc = subprocess.Popen(
            x, stdin=prev.stdout, stdout=subprocess.PIPE, shell=True)
        prev = proc
    output = proc.communicate()[0]
    return output.rstrip()


def getkeyssortedbyvalues(authors):
    recs = [(count, author) for author, count in authors.items()]
    return [x[1] for x in sorted(recs)]


def getkeyssortedbyvaluekey(d, key):
    return map(
        lambda el: el[1], sorted(map(lambda el: (d[el][key], el), d.keys())))

# This should be the main function to extract data from the repository.


def collect(path):
    if len(conf['project_name']) == 0:
        return os.path.basename(os.path.abspath(path))
    return conf['project_name']


def getversion():
    """
    Return commit of current version of gitstats.
    """
    return getpipeoutput(
        ["git rev-parse --short HEAD"]
    ).split('\n')[0]


def getgitversion():
    return getpipeoutput(['git --version']).split('\n')[0]


def getgnuplotversion():
    return getpipeoutput(['gnuplot --version']).split('\n')[0]


class DataCollector(object):

    """Manages data collection from a revision control repository."""

    def __init__(self):
        self.stamp_created = time.time()
        self.cache = {}
        self.total_authors = 0
        self.activity_by_hour_of_day = {}  # hour -> commits
        self.activity_by_day_of_week = {}  # day -> commits
        self.activity_by_month_of_year = {}  # month [1-12] -> commits
        self.activity_by_hour_of_week = {}  # weekday -> hour -> commits
        self.activity_by_hour_of_day_busiest = 0
        self.activity_by_hour_of_week_busiest = 0
        self.activity_by_year_week = {}  # yy_wNN -> commits
        self.activity_by_year_week_peak = 0

        self.authors = defaultdict(
            lambda: {'lines_added': 0, 'lines_removed': 0, 'commits': 0})

        self.total_commits = 0
        self.total_files = 0
        self.authors_by_commits = 0

        # domains
        self.domains = {}  # domain -> commits

        # author of the month
        self.author_of_month = {}  # month -> author -> commits
        self.author_of_year = {}  # year -> author -> commits
        self.commits_by_month = {}  # month -> commits
        self.commits_by_year = {}  # year -> commits
        self.first_commit_stamp = 0
        self.last_commit_stamp = 0
        self.last_active_day = None
        self.active_days = set()

        # lines
        self.total_lines = 0
        self.total_lines_added = 0
        self.total_lines_removed = 0

        # timezone
        self.commits_by_timezone = {}  # timezone -> commits

        # tags
        self.tags = {}

        self.files_by_stamp = {}  # stamp -> files

        # extensions
        self.extensions = defaultdict(lambda: {'files': 0, 'lines': 0})

        # line statistics
        self.changes_by_date = defaultdict(dict)

    # Load cacheable data
    def loadCache(self, cachefile):
        if not os.path.exists(cachefile):
            return
        print 'Loading cache...'
        cache = open(cachefile, 'rb')
        try:
            self.cache = pickle.loads(zlib.decompress(cache.read()))
        except:
            # temporary hack to upgrade non-compressed caches
            cache.seek(0)
            self.cache = pickle.load(cache)
        cache.close()

    def getStampCreated(self):
        return self.stamp_created

    def save_cache(self, cachefile):
        print 'Saving cache...'
        f = open(cachefile, 'wb')
        data = zlib.compress(pickle.dumps(self.cache))
        f.write(data)
        f.close()


class GitDataCollector(DataCollector):

    def collect(self, dir):
        self.projectname = collect(dir)

        self.total_authors += int(
            getpipeoutput(['git shortlog -s HEAD', 'wc -l'])
        )

        # tags
        lines = getpipeoutput(['git show-ref --tags']).split('\n')
        for line in lines:

            if len(line) == 0:
                continue
            (commit, tag) = line.split(' ')

            tag = tag.replace('refs/tags/', '')
            output = getpipeoutput(
                ['git log "%s" --pretty=format:"%%at %%aN" -n 1' % commit])
            if len(output) > 0:
                parts = output.split(' ')
                stamp = 0
                try:
                    stamp = int(parts[0])
                except ValueError:
                    stamp = 0
                self.tags[tag] = {
                    'stamp': stamp, 'hash': commit,
                    'date': datetime.fromtimestamp(stamp).strftime('%Y-%m-%d'),
                    'commits': 0, 'authors': {}
                }

        # collect info on tags, starting from latest
        tags_sorted_by_date_desc = map(lambda el: el[1], reversed(
            sorted(map(lambda el: (el[1]['date'], el[0]), self.tags.items()))))
        prev = None
        for tag in reversed(tags_sorted_by_date_desc):
            cmd = 'git shortlog -s "%s"' % tag
            if prev is not None:
                cmd += ' "^%s"' % prev
            output = getpipeoutput([cmd])
            if len(output) == 0:
                continue
            prev = tag
            for line in output.split('\n'):
                parts = re.split('\s+', line, 2)
                commits = int(parts[1])
                author = parts[2]
                self.tags[tag]['commits'] = commits
                self.tags[tag]['authors'][author] = commits

        # Collect revision statistics
        # Outputs "<stamp> <date> <time> <timezone> <author> '<' <mail> '>'"
        lines = getpipeoutput([
            'git rev-list --pretty=format:"%at %ai %aN <%aE>" HEAD',
            'grep -v ^commit'
        ]).split('\n')
        for line in lines:
            parts = line.split(' ', 4)
            author = ''
            try:
                stamp = int(parts[0])
            except ValueError:
                stamp = 0
            timezone = parts[3]
            author, mail = parts[4].split('<', 1)
            author = author.rstrip()
            mail = mail.rstrip('>')
            domain = '?'
            if mail.find('@') != -1:
                domain = mail.rsplit('@', 1)[1]
            date = datetime.fromtimestamp(float(stamp))

            # First and last commit stamp (may be in any order because of
            # cherry-picking and patches)
            if stamp > self.last_commit_stamp:
                self.last_commit_stamp = stamp
            if self.first_commit_stamp == 0 or stamp < self.first_commit_stamp:
                self.first_commit_stamp = stamp

            # activity
            # hour
            hour = date.hour
            self.activity_by_hour_of_day[
                hour] = self.activity_by_hour_of_day.get(hour, 0) + 1
            # most active hour?
            if self.activity_by_hour_of_day[
                    hour] > self.activity_by_hour_of_day_busiest:
                self.activity_by_hour_of_day_busiest = \
                    self.activity_by_hour_of_day[hour]

            # day of week
            day = date.weekday()
            self.activity_by_day_of_week[
                day] = self.activity_by_day_of_week.get(day, 0) + 1

            # domain stats
            if domain not in self.domains:
                self.domains[domain] = {}
            # commits
            self.domains[domain]['commits'] = self.domains[
                domain].get('commits', 0) + 1

            # hour of week
            if day not in self.activity_by_hour_of_week:
                self.activity_by_hour_of_week[day] = {}
            self.activity_by_hour_of_week[day][
                hour] = self.activity_by_hour_of_week[day].get(hour, 0) + 1
            # most active hour?
            if self.activity_by_hour_of_week[day][
                    hour] > self.activity_by_hour_of_week_busiest:
                self.activity_by_hour_of_week_busiest = \
                    self.activity_by_hour_of_week[day][hour]

            # month of year
            month = date.month
            self.activity_by_month_of_year[
                month] = self.activity_by_month_of_year.get(month, 0) + 1

            # yearly/weekly activity
            yyw = date.strftime('%Y-%W')
            self.activity_by_year_week[
                yyw] = self.activity_by_year_week.get(yyw, 0) + 1
            if self.activity_by_year_week_peak < self.activity_by_year_week[
                    yyw]:
                self.activity_by_year_week_peak = self.activity_by_year_week[
                    yyw]

            # author stats
            # commits, note again that commits may be in any date order because
            # of cherry-picking and patches
            if 'last_commit_stamp' not in self.authors[author]:
                self.authors[author]['last_commit_stamp'] = stamp
            if stamp > self.authors[author]['last_commit_stamp']:
                self.authors[author]['last_commit_stamp'] = stamp
            if 'first_commit_stamp' not in self.authors[author]:
                self.authors[author]['first_commit_stamp'] = stamp
            if stamp < self.authors[author]['first_commit_stamp']:
                self.authors[author]['first_commit_stamp'] = stamp

            # author of the month/year
            yymm = date.strftime('%Y-%m')
            if yymm in self.author_of_month:
                self.author_of_month[yymm][author] = self.author_of_month[
                    yymm].get(author, 0) + 1
            else:
                self.author_of_month[yymm] = {}
                self.author_of_month[yymm][author] = 1
            self.commits_by_month[
                yymm] = self.commits_by_month.get(yymm, 0) + 1

            year = date.year
            if year in self.author_of_year:
                self.author_of_year[year][author] = self.author_of_year[
                    year].get(author, 0) + 1
            else:
                self.author_of_year[year] = {}
                self.author_of_year[year][author] = 1
            self.commits_by_year[year] = self.commits_by_year.get(year, 0) + 1

            # authors: active days
            yymmdd = date.strftime('%Y-%m-%d')
            if 'last_active_day' not in self.authors[author]:
                self.authors[author]['last_active_day'] = yymmdd
                self.authors[author]['active_days'] = set([yymmdd])
            elif yymmdd != self.authors[author]['last_active_day']:
                self.authors[author]['last_active_day'] = yymmdd
                self.authors[author]['active_days'].add(yymmdd)

            # project: active days
            if yymmdd != self.last_active_day:
                self.last_active_day = yymmdd
                self.active_days.add(yymmdd)

            # timezone
            self.commits_by_timezone[
                timezone] = self.commits_by_timezone.get(timezone, 0) + 1

        # TODO Optimize this, it's the worst bottleneck
        # outputs "<stamp> <files>" for each revision
        revlines = getpipeoutput([
            'git rev-list --pretty=format:"%at %T" HEAD',
            'grep -v ^commit'
        ]).strip().split('\n')
        lines = []
        for revline in revlines:
            time, rev = revline.split(' ')
            linecount = self.files_in_commit(rev)
            lines.append('%d %d' % (int(time), linecount))

        self.total_commits += len(lines)
        for line in lines:
            parts = line.split(' ')
            if len(parts) != 2:
                continue
            (stamp, files) = parts[0:2]
            try:
                self.files_by_stamp[int(stamp)] = int(files)
            except ValueError:
                print 'Warning: failed to parse line "%s"' % line

        # extensions
        lines = getpipeoutput([
            'git ls-tree -r -z HEAD'
        ]).split('\000')

        for line in lines:
            if len(line) == 0:
                continue

            sha1, fullpath = line.split()[2:4]

            # skip directories we aren't interested in
            if len(conf['exclude_directories']):
                if any(dir in fullpath for dir in conf['exclude_directories'].split(',')):
                    continue

            filename = os.path.basename(fullpath)  # strip directories

            try:
                ext = filename.split(os.extsep)[-1]
            except IndexError as ex:
                ext = ''

            # skip extensions we aren't interested in
            if len(ext) and len(conf['exclude_extensions']):
                if ext in conf['exclude_extensions'].split(','):
                    continue

            self.extensions[ext]['files'] += 1
            try:
                self.extensions[ext]['lines'] += self.getLinesInBlob(sha1)
            except ValueError as ex:
                print "this is messed up! {0}".format(ex)
            self.total_files += 1

        self.changes_by_date = {}  # stamp -> { files, ins, del }
        extra = '--first-parent -m'

        lines = getpipeoutput([
            'git log --numstat %s --pretty=format:"%%at %%aN" HEAD' %
            (extra)
        ]).split('\n')

        lines.reverse()
        files = 0
        inserted = 0
        deleted = 0
        total_lines = 0
        author = None
        file_pattern = re.compile(r'^(\d+)\s+(\d+)\s+(.*)\s*$')
        for line in lines:

            # empty lines
            if len(line.strip()) == 0:
                continue

            # binary file
            if line.startswith('-'):
                continue

            matches = file_pattern.search(line)
            if matches:

                inserted, deleted, filename = matches.groups()
                inserted = int(inserted)
                deleted = int(deleted)

                try:
                    ext = filename.split(os.extsep)[-1]
                except IndexError as ex:
                    ext = ''

                # ignore files we don't care about
                if len(ext) and len(conf['exclude_extensions']):
                    if ext in conf['exclude_extensions'].split(','):
                        continue

                total_lines += inserted
                total_lines -= deleted
                self.total_lines_added += inserted
                self.total_lines_removed += deleted

            else:
                stamp = int(line.split()[0])
                self.changes_by_date[stamp] = {
                    'files': files,
                    'ins': inserted,
                    'del': deleted,
                    'lines': total_lines}
                files, inserted, deleted = 0, 0, 0

        self.total_lines = total_lines

        # Per-author statistics

        # defined for stamp, author only if author commited at this timestamp.
        self.auth_chg_by_date = defaultdict(dict)

        # Similar to the above, but never use --first-parent
        # (we need to walk through every commit to know who
        # committed what, not just through mainline)

        lines = getpipeoutput([
            'git log --numstat --date-order --pretty=format:"%at %aN" HEAD'
        ]).split('\n')
        lines.reverse()
        files = 0
        inserted = 0
        deleted = 0
        author = None
        stamp = 0
        for line in lines:
            if len(line.strip()) == 0:
                continue

            # binary file
            if line.startswith('-'):
                continue

            matches = file_pattern.search(line)
            if matches:

                inserted, deleted, filename = matches.groups()
                inserted, deleted = int(inserted), int(deleted)

                try:
                    ext = filename.split(os.extsep)[-1]
                except IndexError as ex:
                    ext = ''

                # ignore files we don't care about
                if len(ext) and len(conf['exclude_extensions']):
                    if ext in conf['exclude_extensions'].split(','):
                        continue

                files += 1

            else:
                oldstamp = stamp
                stamp = int(line.split()[0])
                author = ' '.join(line.split()[1:])

                if oldstamp > stamp:
                    # clock skew, keep old timestamp to avoid having ugly graph
                    stamp = oldstamp

                self.authors[author]['commits'] += 1
                self.authors[author]['lines_added'] += inserted
                self.authors[author]['lines_removed'] += deleted

                if author not in self.auth_chg_by_date[stamp]:
                    self.auth_chg_by_date[stamp][author] = dict()
                self.auth_chg_by_date[stamp][author][
                    'lines_added'] = self.authors[author]['lines_added']
                self.auth_chg_by_date[stamp][author][
                    'commits'] = self.authors[author]['commits']
                files, inserted, deleted = 0, 0, 0

    def refine(self):
        # authors
        # name -> {place_by_commits, commits_frac, date_first, date_last,
        # timedelta}
        self.authors_by_commits = getkeyssortedbyvaluekey(
            self.authors,
            'commits')
        self.authors_by_commits.reverse()  # most first
        for i, name in enumerate(self.authors_by_commits):
            self.authors[name]['place_by_commits'] = i + 1

        for name in self.authors.keys():
            author = self.authors[name]
            author['commits_frac'] = (
                100 * float(author['commits'])) / self.get_total_commits()
            date_first = datetime.fromtimestamp(author['first_commit_stamp'])
            date_last = datetime.fromtimestamp(author['last_commit_stamp'])
            delta = date_last - date_first
            author['date_first'] = date_first.strftime('%Y-%m-%d')
            author['date_last'] = date_last.strftime('%Y-%m-%d')
            author['timedelta'] = delta
            if 'lines_added' not in author:
                author['lines_added'] = 0
            if 'lines_removed' not in author:
                author['lines_removed'] = 0

    def get_active_days(self):
        return self.active_days

    def get_activity_by_dow(self):
        return self.activity_by_day_of_week

    def getActivityByHourOfDay(self):
        return self.activity_by_hour_of_day

    def getAuthorInfo(self, author):
        return self.authors[author]

    def getAuthors(self, limit=None):
        res = getkeyssortedbyvaluekey(self.authors, 'commits')
        res.reverse()
        return res[:limit]

    def get_commit_delta_days(self):
        """
        Return the number of days between commits.
        """
        return (self.last_commit_stamp - self.first_commit_stamp) / 86400 + 1

    def get_domain_info(self, domain):
        return self.domains[domain]

    def files_in_commit(self, rev):
        try:
            res = self.cache['files_in_tree'][rev]
        except:
            res = int(
                getpipeoutput(
                    ['git ls-tree -r --name-only "%s"' %
                     rev, 'wc -l']).split('\n')[0]
            )
            if 'files_in_tree' not in self.cache:
                self.cache['files_in_tree'] = {}
            self.cache['files_in_tree'][rev] = res

        return res

    def getFirstCommitDate(self):
        return datetime.fromtimestamp(self.first_commit_stamp)

    def getLastCommitDate(self):
        return datetime.fromtimestamp(self.last_commit_stamp)

    def getLinesInBlob(self, sha1):
        try:
            res = self.cache['lines_in_blob'][sha1]
        except:
            res = int(
                getpipeoutput(
                    ['git cat-file blob %s' % sha1, 'wc -l']).split()[0])
            if 'lines_in_blob' not in self.cache:
                self.cache['lines_in_blob'] = {}
            self.cache['lines_in_blob'][sha1] = res
        return res

    def getTags(self):
        lines = getpipeoutput(['git show-ref --tags', 'cut -d/ -f3'])
        return lines.split('\n')

    def get_total_authors(self):
        return self.total_authors

    def get_total_commits(self):
        return self.total_commits

    def get_total_files(self):
        return self.total_files

    def total_loc(self):
        return self.total_lines


def html_header(level, text):
    """
    Return a string for the HTML header.
    """
    name = urllib.quote(text)
    return '\n<h%d><a href="#%s" name="%s">%s</a></h%d>\n\n' % (
        level, name, name, text, level)


class HTMLReportCreator(object):

    def __init__(self, data, path):
        """
        Initialize a new HTMLReportCreator.
        """
        self.data = data
        self.path = path
        self.title = data.projectname
        self.authors_to_plot = None

    def create(self):
        """
        Make the HTML files.
        """

        data = self.data
        path = self.path

        # copy static files. Looks in the binary directory, ../share/gitstats
        # and /usr/share/gitstats
        binarypath = os.path.dirname(os.path.abspath(__file__))
        secondarypath = os.path.join(binarypath, '..', 'share', 'gitstats')
        basedirs = [binarypath, secondarypath, '/usr/share/gitstats']
        for filename in ('gitstats.css', 'sortable.js',
                         'arrow-up.gif', 'arrow-down.gif', 'arrow-none.gif'):
            for base in basedirs:
                src = os.path.join(base, filename)
                if os.path.exists(src):
                    shutil.copyfile(src, os.path.join(path, filename))
                    break
            else:
                msg = 'Warning: "{0}" not found, so not copied (searched: {1})'
                print msg.format(filename, basedirs)

        outfile = open(os.path.join(path, "index.html"), 'w')
        date_format = '%Y-%m-%d %H:%M:%S'
        self.print_header(outfile)

        out = []
        out.append('<h1>GitStats - %s</h1>' % data.projectname)
        out.append(print_nav())
        out.append('<dl class="dl-horizontal">')
        out.append('<dt>Project name</dt><dd>%s</dd>' % (data.projectname))
        out.append(
            '<dt>Generated</dt><dd>%s (in %d seconds)</dd>' %
            (datetime.now().strftime(date_format),
             time.time() -
             data.getStampCreated()))
        out.append(
            (
                '<dt>Generator</dt><dd>'
                '<a href="http://gitstats.sourceforge.net/">GitStats</a> '
                '(version %s), %s, %s</dd>'
            ) %
            (getversion(), getgitversion(), getgnuplotversion()))
        out.append(
            '<dt>Report Period</dt><dd>%s to %s</dd>' %
            (data.getFirstCommitDate().strftime(date_format),
             data.getLastCommitDate().strftime(date_format)))
        out.append('<dt>Age</dt><dd>%d days, %d active days (%3.2f%%)</dd>' %
                   (
                       data.get_commit_delta_days(),
                       len(data.get_active_days()),
                       (
                           100.0 * len(data.get_active_days()) /
                           data.get_commit_delta_days()
                       )
                   ))
        out.append('<dt>Total Files</dt><dd>%s</dd>' % data.get_total_files())
        out.append(
            '<dt>Total Lines of Code</dt><dd>%s (%d added, %d removed)</dd>' %
            (data.total_loc(),
             data.total_lines_added,
             data.total_lines_removed))
        msg = (
            '<dt>Total Commits</dt><dd>%s '
            '(average %.1f commits per active day, '
            '%.1f per all days)</dd>'
        )
        out.append(
            msg %
            (
                data.get_total_commits(), float(
                    data.get_total_commits()) / len(
                    data.get_active_days()), float(
                    data.get_total_commits()) / data.get_commit_delta_days())
        )
        out.append(
            '<dt>Authors</dt><dd>%s (average %.1f commits per author)</dd>' %
            (
                data.get_total_authors(),
                (1.0 * data.get_total_commits()) / data.get_total_authors()
            )
        )
        out.append('</dl>')

        out.append('</body>\n</html>')
        outfile.write('\n'.join(out))
        outfile.close()

        ###
        # Activity
        outfile = open(path + '/activity.html', 'w')
        out = []
        self.print_header(outfile)
        out.append('<h1>Activity</h1>')
        out.append(print_nav())

        # Weekly activity
        num_weeks = 32
        out.append(html_header(2, 'Weekly activity'))
        out.append('<p>Last %d weeks</p>' % num_weeks)

        # generate weeks to show (previous N weeks from now)
        now = datetime.now()
        deltaweek = timedelta(days=7)
        weeks = []
        stampcur = now
        for i in range(0, num_weeks):
            weeks.insert(0, stampcur.strftime('%Y-%W'))
            stampcur -= deltaweek

        # top row: commits & bar
        out.append('<table class="table tight-table"><tr>')
        for i in range(0, num_weeks):
            commits = 0
            if weeks[i] in data.activity_by_year_week:
                commits = data.activity_by_year_week[weeks[i]]

            percentage = 0
            if weeks[i] in data.activity_by_year_week:
                percentage = float(
                    data.activity_by_year_week[
                        weeks[i]]) / data.activity_by_year_week_peak
            height = max(1, int(200 * percentage))
            out.append(
                '<td style="text-align: center; vertical-align: bottom">'
                '{0}<div style="display: block; '
                'background-color:  hsl(206, 90%, 50%);'
                'width: 20px; height: {1}px"></div></td>'.format(
                    commits, height
                )
            )

        # bottom row: year/week
        out.append('</tr><tr>')
        for i in range(0, num_weeks):
            out.append('<td>%s</td>' % (num_weeks - i))
        out.append('</tr></table>')

        # Hour of Day
        out.append(html_header(2, 'Hour of Day'))
        hour_of_day = data.getActivityByHourOfDay()
        out.append('<table class="table tight-table"><tr><th>Hour</th>')
        for i in range(0, 24):
            out.append('<th>%d</th>' % i)
        out.append('</tr>\n<tr><th>Commits</th>')
        filehandle = open(path + '/hour_of_day.dat', 'w')
        out2 = []
        for i in range(0, 24):
            if i in hour_of_day:
                lightness = 100 - int(
                    (
                        float(hour_of_day[i]) /
                        data.activity_by_hour_of_day_busiest
                    ) * 50
                )
                snippet = (
                    '<td style="background-color: '
                    'hsl(206, 90%, {0}%)">{1}</td>'
                )
                out.append(
                    snippet.format(
                        lightness, hour_of_day[i]
                    )
                )
                out2.append('%d %d\n' % (i, hour_of_day[i]))
            else:
                out.append('<td>0</td>')
                out2.append('%d 0\n' % i)
        filehandle.write('\n'.join(out2))
        del out2
        filehandle.close()
        out.append('</tr>\n<tr><th>%</th>')
        totalcommits = data.get_total_commits()
        for i in range(0, 24):
            if i in hour_of_day:
                lightness = 100 - \
                    int((float(hour_of_day[i]) /
                         data.activity_by_hour_of_day_busiest) * 50)
                snippet = (
                    '<td style="background-color: '
                    'hsl(206, 90%, {0}%)">{1:.1f}</td>'
                )
                out.append(
                    snippet.format(
                        lightness, (100.0 * hour_of_day[i]) / totalcommits))
            else:
                out.append('<td>0</td>')
        out.append('</tr></table>')
        out.append('<img src="hour_of_day.png" alt="Hour of Day" />')
        hours_file = open(path + '/hour_of_day.dat', 'w')
        out2 = []
        for i in range(0, 24):
            if i in hour_of_day:
                out2.append('%d %d\n' % (i + 1, hour_of_day[i]))
            else:
                out2.append('%d 0\n' % (i + 1))
        hours_file.write('\n'.join(out2))
        del out2
        hours_file.close()

        # Day of Week
        out.append(html_header(2, 'Day of Week'))
        day_of_week = data.get_activity_by_dow()
        out.append('<table class="table vertical-table">')
        out.append('<tr><th>Day</th><th>Total (%)</th></tr>')
        dow_file = open(path + '/day_of_week.dat', 'w')
        out2 = []
        for i in range(0, 7):
            commits = 0
            if i in day_of_week:
                commits = day_of_week[i]
            out2.append('%d %s %d\n' % (i + 1, WEEKDAYS[i], commits))
            out.append('<tr>')
            out.append('<th>%s</th>' % (WEEKDAYS[i]))
            if i in day_of_week:
                out.append(
                    '<td>%d (%.2f%%)</td>' %
                    (day_of_week[i], (100.0 * day_of_week[i]) / totalcommits))
            else:
                out.append('<td>0</td>')
            out.append('</tr>')
        out.append('</table>')
        out.append('<img src="day_of_week.png" alt="Day of Week" />')
        dow_file.write('\n'.join(out2))
        del out2
        dow_file.close()

        # Hour of Week
        out.append(html_header(2, 'Hour of Week'))
        out.append('<table class="table square-table">')

        out.append('<tr><th>Weekday</th>')
        for hour in range(0, 24):
            out.append('<th>%d</th>' % (hour))
        out.append('</tr>')

        for weekday in range(0, 7):
            out.append('<tr><th>%s</th>' % (WEEKDAYS[weekday]))
            for hour in range(0, 24):
                try:
                    commits = data.activity_by_hour_of_week[weekday][hour]
                except KeyError:
                    commits = 0
                if commits != 0:
                    out.append('<td')
                    lightness = 100 - \
                        int((float(commits) /
                             data.activity_by_hour_of_week_busiest) * 50)
                    out.append(
                        ' style="background-color: hsl(206, 90%%, %d%%)"' %
                        lightness)
                    out.append('>%d</td>' % commits)
                else:
                    out.append('<td></td>')
            out.append('</tr>')

        out.append('</table>')

        # Month of Year
        out.append(html_header(2, 'Month of Year'))
        out.append('<table class="table vertical-table">')
        out.append('<tr><th>Month</th><th>Commits (%)</th></tr>')
        moy_file = open(path + '/month_of_year.dat', 'w')
        out2 = []
        for i in range(1, 13):
            commits = 0
            if i in data.activity_by_month_of_year:
                commits = data.activity_by_month_of_year[i]
            out.append(
                '<tr><td>%d</td><td>%d (%.2f %%)</td></tr>' %
                (i, commits, (100.0 * commits) / data.get_total_commits()))
            out2.append('%d %d\n' % (i, commits))
        moy_file.write('\n'.join(out2))
        del out2
        moy_file.close()
        out.append('</table>')
        out.append('<img src="month_of_year.png" alt="Month of Year" />')

        # Commits by year/month
        out.append(html_header(2, 'Commits by year/month'))
        out.append(
            (
                '<table class="table vertical-table"><tr><th>Month</th>'
                '<th>Commits</th></tr>'
            )
        )
        for yymm in reversed(sorted(data.commits_by_month.keys())):
            out.append(
                '<tr><td>%s</td><td>%d</td></tr>' %
                (yymm, data.commits_by_month[yymm]))
        out.append('</table>')
        out.append(
            '<img src="commits_by_year_month.png" '
            'alt="Commits by year/month" />'
        )
        cby_file = open(path + '/commits_by_year_month.dat', 'w')
        out2 = []
        for yymm in sorted(data.commits_by_month.keys()):
            out2.append('%s %s\n' % (yymm, data.commits_by_month[yymm]))
        cby_file.write('\n'.join(out2))
        del out2
        cby_file.close()

        # Commits by year
        out.append(html_header(2, 'Commits by Year'))

        out.append(
            '<table class="table vertical-table"><tr><th>Year</th>'
            '<th>Commits (% of all)</th></tr>'
        )
        for year in reversed(sorted(data.commits_by_year.keys())):
            out.append(
                '<tr><td>%s</td><td>%d (%.2f%%)</td></tr>' %
                (year,
                 data.commits_by_year[year],
                 (100.0 *
                  data.commits_by_year[year]) /
                    data.get_total_commits()))
        out.append('</table>')
        out.append('<img src="commits_by_year.png" alt="Commits by Year" />')
        cby_out = open(path + '/commits_by_year.dat', 'w')
        out2 = []
        for year in sorted(data.commits_by_year.keys()):
            out2.append('%d %d\n' % (year, data.commits_by_year[year]))
        cby_out.write('\n'.join(out2))
        del out2
        cby_out.close()

        # Commits by timezone
        out.append(html_header(2, 'Commits by Timezone'))
        out.append('<table class="table"><tr>')
        out.append('<th>Timezone</th><th>Commits</th>')
        max_commits_on_tz = max(data.commits_by_timezone.values())
        for i in sorted(data.commits_by_timezone.keys(), key=lambda n: int(n)):
            commits = data.commits_by_timezone[i]
            lightness = 100 - int((float(commits) / max_commits_on_tz) * 50)
            out.append(
                '<tr><th>%s</th><td '
                'style="background-color: hsl(206, 90%%, %d%%)"'
                '>%d</td></tr>' % (i, lightness, commits))
        out.append('</body></html>')
        outfile.write('\n'.join(out))
        outfile.close()

        ###
        # Authors
        out = []
        outfile = open(path + '/authors.html', 'w')
        self.print_header(outfile)

        out.append('<h1>Authors</h1>')
        out.append(print_nav())

        # Authors :: List of authors
        out.append(html_header(2, 'List of Authors'))

        out.append('<table class="table authors sortable" id="authors">')
        out.append((
            '<tr><th>Author</th><th>Commits (%)</th><th>+ lines</th><th>- '
            'lines</th><th>First commit</th><th>Last commit</th><th '
            'class="unsortable">Age</th><th>Active days</th><th># '
            'by commits</th></tr>'
        ))

        for author in data.getAuthors(conf['max_authors']):
            info = data.getAuthorInfo(author)
            out.append((
                '<tr><td>%s</td><td>%d (%.2f%%)</td><td>%d</td><td>%d</td>'
                '<td>%s</td><td>%s</td><td>%s</td><td>%d</td><td>%d</td></tr>'
            ) % (
                author,
                info['commits'],
                info['commits_frac'],
                info['lines_added'],
                info['lines_removed'],
                info['date_first'],
                info['date_last'],
                info['timedelta'],
                len(info['active_days']),
                info['place_by_commits'],
            ))
        out.append('</table>')

        allauthors = data.getAuthors()
        if len(allauthors) > conf['max_authors']:
            rest = allauthors[conf['max_authors']:]
            out.append((
                "<p class='moreauthors'>These didn't make it to "
                "the top: %s</p>"
            ) % ', '.join(rest))

        out.append(html_header(2, 'Cumulated Added Lines of Code per Author'))
        out.append(
            '<img src="lines_of_code_by_author.png" '
            'alt="Lines of code per Author" />'
        )
        if len(allauthors) > conf['max_authors']:
            out.append(
                '<p class="moreauthors">Only top %d authors shown</p>' %
                conf['max_authors'])

        out.append(html_header(2, 'Commits per Author'))
        out.append(
            '<img src="commits_by_author.png" alt="Commits per Author" />')
        if len(allauthors) > conf['max_authors']:
            out.append(
                '<p class="moreauthors">Only top %d authors shown</p>' %
                conf['max_authors'])

        fgl = open(path + '/lines_of_code_by_author.dat', 'w')
        out_fgl = []
        fgc = open(path + '/commits_by_author.dat', 'w')
        out_fgc = []

        lines_by_authors = {}  # cumulated added lines by
        # author. to save memory,
        # auth_chg_by_date[stamp][author] is defined
        # only at points where author commits.
        # lines_by_authors allows us to generate all the
        # points in the .dat file.

        # Don't rely on getAuthors to give the same order each
        # time. Be robust and keep the list in a variable.
        cmt_by_auth = {}  # cumulated added lines by

        self.authors_to_plot = data.getAuthors(conf['max_authors'])
        for author in self.authors_to_plot:
            lines_by_authors[author] = 0
            cmt_by_auth[author] = 0
        for stamp in sorted(data.auth_chg_by_date.keys()):
            out_fgl.append('%d' % stamp)
            out_fgc.append('%d' % stamp)
            for author in self.authors_to_plot:
                if author in data.auth_chg_by_date[stamp].keys():
                    lines_by_authors[author] = data.auth_chg_by_date[
                        stamp][author]['lines_added']
                    cmt_by_auth[author] = \
                        data.auth_chg_by_date[stamp][author]['commits']
                out_fgl.append(' %d' % lines_by_authors[author])
                out_fgc.append(' %d' % cmt_by_auth[author])
            out_fgl.append('\n')
            out_fgc.append('\n')

        fgl.write(''.join(out_fgl))
        fgc.write(''.join(out_fgc))
        del out_fgl
        del out_fgc
        fgl.close()
        fgc.close()

        # Authors :: Author of Month
        out.append(html_header(2, 'Author of Month'))
        out.append('<table class="table sortable" id="aom">')
        snippet = (
            '<tr><th>Month</th><th>Author</th><th>Commits (%%)</th>'
            '<th class="unsortable">Next top %d</th>'
            '<th>Number of authors</th></tr>'
        )
        out.append(snippet % conf['authors_top'])
        for yymm in reversed(sorted(data.author_of_month.keys())):
            authordict = data.author_of_month[yymm]
            authors = getkeyssortedbyvalues(authordict)
            authors.reverse()
            commits = data.author_of_month[yymm][authors[0]]
            next_author = ', '.join(authors[1:conf['authors_top'] + 1])
            snippet = (
                '<tr><td>%s</td><td>%s</td><td>%d (%.2f%% of %d)</td>'
                '<td>%s</td><td>%d</td></tr>'
            )
            out.append(
                snippet %
                (
                    yymm,
                    authors[0],
                    commits,
                    (100.0 * commits) / data.commits_by_month[yymm],
                    data.commits_by_month[yymm],
                    next_author,
                    len(authors),
                )
            )

        out.append('</table>')

        out.append(html_header(2, 'Author of Year'))
        snippet = (
            '<table class="table sortable" id="aoy"><tr><th>Year</th>'
            '<th>Author</th><th>Commits (%%)</th>'
            '<th class="unsortable">Next top %d</th>'
            '<th>Number of authors</th></tr>'
        )
        out.append(
            snippet % conf['authors_top'])
        for year in reversed(sorted(data.author_of_year.keys())):
            authordict = data.author_of_year[year]
            authors = getkeyssortedbyvalues(authordict)
            authors.reverse()
            commits = data.author_of_year[year][authors[0]]
            next_author = ', '.join(authors[1:conf['authors_top'] + 1])
            out.append(
                ('<tr><td>%s</td><td>%s</td><td>%d (%.2f%% of %d)</td>'
                 '<td>%s</td><td>%d</td></tr>') %
                (
                    year,
                    authors[0],
                    commits,
                    (100.0 * commits) /
                    data.commits_by_year[year],
                    data.commits_by_year[year],
                    next_author,
                    len(authors)
                )
            )
        out.append('</table>')

        # Domains
        out.append(html_header(2, 'Commits by Domains'))
        domains_by_commits = getkeyssortedbyvaluekey(data.domains, 'commits')
        domains_by_commits.reverse()  # most first
        out.append('<table class="table vertical-table">')
        out.append('<tr><th>Domains</th><th>Total (%)</th></tr>')
        domain_file = open(path + '/domains.dat', 'w')
        out2 = []
        i = 0
        for domain in domains_by_commits:
            if i == conf['max_domains']:
                break
            commits = 0

            i += 1
            info = data.get_domain_info(domain)
            out2.append('%s %d %d\n' % (domain, i, info['commits']))
            out.append(
                '<tr><th>%s</th><td>%d (%.2f%%)</td></tr>' %
                (
                    domain, info['commits'],
                    (100.0 * info['commits'] / totalcommits)
                )
            )

        out.append('</table>')
        out.append('<img src="domains.png" alt="Commits by Domains" />')
        domain_file.write('\n'.join(out2))
        del out2
        domain_file.close()

        out.append('</body></html>')

        outfile.write('\n'.join(out))
        outfile.close()

        ###
        # Files
        out = []
        outfile = open(path + '/files.html', 'w')
        self.print_header(outfile)
        out.append('<h1>Files</h1>')
        out.append(print_nav())

        out.append('<dl>\n')
        out.append('<dt>Total files</dt><dd>%d</dd>' % data.get_total_files())
        out.append('<dt>Total lines</dt><dd>%d</dd>' % data.total_loc())

        try:
            average_size = (100.0 * data.total_loc()) / data.get_total_files()
        except ZeroDivisionError:
            average_size = 0.0
        out.append(
            '<dt>Average file size</dt><dd>%.2f bytes</dd>' %
            (average_size))
        out.append('</dl>\n')

        # Files :: File count by date
        out.append(html_header(2, 'File count by date'))

        # use set to get rid of duplicate/unnecessary entries
        files_by_date = set()
        for stamp in sorted(data.files_by_stamp.keys()):
            files_by_date.add(
                '%s %d' %
                (datetime.fromtimestamp(stamp).strftime('%Y-%m-%d'),
                 data.files_by_stamp[stamp]))

        fbd_file = open(path + '/files_by_date.dat', 'w')
        out2 = []
        for line in sorted(list(files_by_date)):
            out2.append(line)
        fbd_file.write('\n'.join(out2))
        del out2
        fbd_file.close()

        out.append('<img src="files_by_date.png" alt="Files by Date" />')

        # Files :: Extensions
        out.append(html_header(2, 'Extensions'))
        out.append((
            '<table class="table sortable" id="ext"><tr>'
            '<th>Extension</th><th>Files (%)</th><th>Lines (%)</th>'
            '<th>Lines/file</th></tr>'
        ))
        for ext in sorted(data.extensions.keys()):
            files = data.extensions[ext]['files']
            lines = data.extensions[ext]['lines']

            try:
                ext_pct = (100.0 * files) / data.get_total_files()
            except ZeroDivisionError:
                ext_pct = 0.0

            out.append(
                (
                    '<tr><td>%s</td><td>%d (%.2f%%)</td><td>%d '
                    '(%.2f%%)</td><td>%d</td></tr>'
                ) %
                (
                    ext, files, ext_pct, lines,
                    (100.0 * lines) / data.total_loc(), lines / files
                )
            )
        out.append('</table>')

        out.append('</body></html>')
        outfile.write('\n'.join(out))
        outfile.close()

        ###
        # Lines
        outfile = open(path + '/lines.html', 'w')
        out = []
        self.print_header(outfile)
        out.append('<h1>Lines</h1>')
        out.append(print_nav())

        out.append('<dl>\n')
        out.append('<dt>Total lines</dt><dd>%d</dd>' % data.total_loc())
        out.append('</dl>\n')

        out.append(html_header(2, 'Lines of Code'))
        out.append('<img src="lines_of_code.png" />')

        loc_file = open(path + '/lines_of_code.dat', 'w')
        out2 = []
        for stamp in sorted(data.changes_by_date.keys()):
            out2.append(
                '%d %d' %
                (stamp, data.changes_by_date[stamp]['lines']))
        loc_file.write('\n'.join(out2))
        del out2
        loc_file.close()

        out.append('</body></html>')
        outfile.write('\n'.join(out))
        outfile.close()

        ###
        # tags.html
        out = []
        outfile = open(path + '/tags.html', 'w')
        self.print_header(outfile)
        out.append('<h1>Tags</h1>')
        out.append(print_nav())

        out.append('<dl>')
        out.append('<dt>Total tags</dt><dd>%d</dd>' % len(data.tags))
        if len(data.tags) > 0:
            out.append('<dt>Average commits per tag</dt><dd>%.2f</dd>' %
                       (1.0 * data.get_total_commits() / len(data.tags)))
        out.append('</dl>')

        out.append('<table class="table tags">')
        out.append((
            '<tr><th>Name</th><th>Date</th>'
            '<th>Commits</th><th>Authors</th></tr>'
        ))

        # sort the tags by date desc
        tags_sorted_by_date_desc = map(lambda el: el[1], reversed(
            sorted(map(lambda el: (el[1]['date'], el[0]), data.tags.items()))))
        for tag in tags_sorted_by_date_desc:
            authorinfo = []
            self.authors_by_commits = getkeyssortedbyvalues(
                data.tags[tag]['authors'])
            for i in reversed(self.authors_by_commits):
                authorinfo.append(
                    '%s (%d)' %
                    (i, data.tags[tag]['authors'][i]))
            out.append(
                '<tr><td>%s</td><td>%s</td><td>%d</td><td>%s</td></tr>' %
                (
                    tag, data.tags[tag]['date'],
                    data.tags[tag]['commits'], ', '.join(authorinfo)
                )
            )
        out.append('</table>')

        out.append('</body></html>')
        outfile.write('\n'.join(out))
        outfile.close()

        self.create_graphs(path)

    def create_graphs(self, path):
        """
        Build gnuplot graphs.
        """
        print 'Generating graphs...'

        # hour of day
        out = open(path + '/hour_of_day.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set output 'hour_of_day.png'
unset key
set xrange [0.5:24.5]
set xtics 4
set grid y
set ylabel "Commits"
plot 'hour_of_day.dat' using 1:2:(0.5) w boxes fs solid
""")
        out.close()

        # day of week
        out = open(path + '/day_of_week.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set output 'day_of_week.png'
unset key
set xrange [0.5:7.5]
set xtics 1
set grid y
set ylabel "Commits"
plot 'day_of_week.dat' using 1:3:(0.5):xtic(2) w boxes fs solid
""")
        out.close()

        # Domains
        out = open(path + '/domains.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set output 'domains.png'
unset key
unset xtics
set yrange [0:]
set grid y
set ylabel "Commits"
""")
        out.write((
            "plot 'domains.dat' using 2:3:(0.5) with boxes fs solid, '' "
            "using 2:3:1 with labels rotate by 45 offset 0,1\n"
        ))
        out.close()

        # Month of Year
        out = open(path + '/month_of_year.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set output 'month_of_year.png'
unset key
set xrange [0.5:12.5]
set xtics 1
set grid y
set ylabel "Commits"
plot 'month_of_year.dat' using 1:2:(0.5) w boxes fs solid
""")
        out.close()

        # commits_by_year_month
        out = open(path + '/commits_by_year_month.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set output 'commits_by_year_month.png'
unset key
set xdata time
set timefmt "%Y-%m"
set format x "%Y-%m"
set xtics rotate
set bmargin 5
set grid y
set ylabel "Commits"
plot 'commits_by_year_month.dat' using 1:2:(0.5) w boxes fs solid
""")
        out.close()

        # commits_by_year
        out = open(path + '/commits_by_year.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set output 'commits_by_year.png'
unset key
set xtics 1 rotate
set grid y
set ylabel "Commits"
set yrange [0:]
plot 'commits_by_year.dat' using 1:2:(0.5) w boxes fs solid
""")
        out.close()

        # Files by date
        out = open(path + '/files_by_date.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set output 'files_by_date.png'
unset key
set xdata time
set timefmt "%Y-%m-%d"
set format x "%Y-%m-%d"
set grid y
set ylabel "Files"
set xtics rotate
set ytics autofreq
set bmargin 6
plot 'files_by_date.dat' using 1:2 w steps
""")
        out.close()

        # Lines of Code
        out = open(path + '/lines_of_code.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set output 'lines_of_code.png'
unset key
set xdata time
set timefmt "%s"
set format x "%Y-%m-%d"
set grid y
set ylabel "Lines"
set xtics rotate
set bmargin 6
plot 'lines_of_code.dat' using 1:2 w lines
""")
        out.close()

        # Lines of Code Added per author
        out = open(path + '/lines_of_code_by_author.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set terminal png transparent size 640,480
set output 'lines_of_code_by_author.png'
set key left top
set xdata time
set timefmt "%s"
set format x "%Y-%m-%d"
set grid y
set ylabel "Lines"
set xtics rotate
set bmargin 6
plot """
        )
        i = 1
        plots = []
        for author in self.authors_to_plot:
            i = i + 1
            plots.append(
                (
                    """'lines_of_code_by_author.dat' """
                    """using 1:%d title "%s" w lines"""
                ) % (i, author.replace("\"", "\\\"")))
        out.write(", ".join(plots))
        out.write('\n')

        out.close()

        # Commits per author
        out = open(path + '/commits_by_author.plot', 'w')
        out.write(GNUPLOT_COMMON)
        out.write(
            """
set terminal png transparent size 640,480
set output 'commits_by_author.png'
set key left top
set xdata time
set timefmt "%s"
set format x "%Y-%m-%d"
set grid y
set ylabel "Commits"
set xtics rotate
set bmargin 6
plot """
        )
        i = 1
        plots = []
        for author in self.authors_to_plot:
            i = i + 1
            plots.append(
                """'commits_by_author.dat' using 1:%d title "%s" w lines""" %
                (i,
                 author.replace(
                     "\"",
                     "\\\"")))
        out.write(", ".join(plots))
        out.write('\n')

        out.close()

        os.chdir(path)
        files = glob.glob(path + '/*.plot')
        for filename in files:
            out = getpipeoutput([gnuplot_cmd + ' "%s"' % filename])
            if len(out) > 0:
                print out

    def print_header(self, output):
        """
        HTML header
        """
        output.write(
            """<html>
<head>
    <title>GitStats - {}</title>
    <meta name="generator" content="GitStats {}" />
    <link rel="stylesheet" href=
    "https://maxcdn.bootstrapcdn.com/bootstrap/3.3.2/css/bootstrap.min.css">
    <link rel="stylesheet" href="{}" type="text/css" />
    <script type="text/javascript" src="sortable.js"></script>
</head>
<body>
<div class="container">
<div class="row">
<div class="col-sm-10 col-sm-offset-1">
""".format(self.title, getversion(), conf['style']))

    def printFooter(self, f):
        f.write("""</div>\n</div>\n</div>\n</body>\n</html>""")


def print_nav():
    """
    Return the HTML for navigation as a string.
    """
    return """
<nav class="navbar navbar-default navbar-fixed-top">
<div class="container">
<div class="navbar-header"></div>
<ul class="nav navbar-nav">
<li><a href="index.html">General</a></li>
<li><a href="activity.html">Activity</a></li>
<li><a href="authors.html">Authors</a></li>
<li><a href="files.html">Files</a></li>
<li><a href="lines.html">Lines</a></li>
<li><a href="tags.html">Tags</a></li>
</ul>
</div>
</nav>
"""


def main(args_orig):
    """
    Run gitstats.
    """
    optlist, args = getopt.getopt(args_orig, 'c:')
    for option, val in optlist:
        if option == '-c':
            key, value = val.split('=', 1)
            if key not in conf:
                raise KeyError('no such key "%s" in config' % key)
            if isinstance(conf[key], int):
                conf[key] = int(value)
            else:
                conf[key] = value
    if len(args) < 2:
        print """

Usage: gitstats [options] <gitpath..> <outputpath>

Options:
-c key=value     Override configuration value

Default config values:
%s
""" % conf
        sys.exit(0)

    outputpath = os.path.abspath(args[-1])
    rundir = os.getcwd()

    try:
        os.makedirs(outputpath)
    except OSError:
        pass
    if not os.path.isdir(outputpath):
        print 'FATAL: Output path is not a directory or does not exist'
        sys.exit(1)

    print 'Output path: %s' % outputpath
    cachefile = os.path.join(tempfile.gettempdir(), 'gitstats.cache')

    data = GitDataCollector()
    data.loadCache(cachefile)

    for gitpath in args[0:-1]:
        print 'Git path: %s' % gitpath

        os.chdir(gitpath)

        print 'Collecting data...'
        data.collect(gitpath)

    print 'Refining data...'
    data.save_cache(cachefile)
    data.refine()

    os.chdir(rundir)

    print 'Generating report...'
    report = HTMLReportCreator(data, outputpath)
    report.create()

if __name__ == '__main__':
    main(sys.argv[1:])
